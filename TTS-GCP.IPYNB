{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🎤 **Proyecto de Síntesis de Texto a Voz usando Google Cloud Text-to-Speech**\n",
    "Este proyecto utiliza la API de Google Cloud Text-to-Speech para convertir texto a voz. La API convierte entradas de texto en archivos de audio, que luego se reproducen directamente en el entorno donde se ejecuta el código. A través de este proyecto, se configuran las credenciales de Google Cloud, se elige una voz, se sintetiza el texto y finalmente se reproduce el archivo de audio generado.\n",
    "\n",
    "🎯 Objetivo\n",
    "El objetivo de este proyecto es integrar la tecnología de síntesis de texto a voz de Google Cloud para desarrollar una solución eficiente y accesible que convierta cualquier texto escrito en una salida de voz natural. A través de la implementación de esta API, se busca explorar y aplicar herramientas avanzadas de IA, ofreciendo una experiencia de interacción más humana con las máquinas. Este proyecto sienta las bases para futuras aplicaciones en áreas como la accesibilidad, asistentes virtuales, y otros sistemas inteligentes que necesiten generar comunicación auditiva a partir de texto. Además, facilita la automatización de procesos y la creación de interfaces interactivas que mejoren la interacción del usuario con sistemas automatizados.\n",
    " _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requisitos\n",
    "\n",
    "Este proyecto necesita las siguientes bibliotecas:\n",
    "\n",
    "- `google-cloud-texttospeech`: Para interactuar con la API de Google Cloud Text-to-Speech.\n",
    "- `playsound`: Para reproducir el archivo de audio generado.\n",
    "\n",
    "Para instalarlas, ejecuta el siguiente comando:\n",
    "\n",
    "```bash\n",
    "pip install google-cloud-texttospeech playsound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de la Autenticación\n",
    "\n",
    "Para utilizar la API de Google Cloud, se necesita configurar la autenticación. se Debe crear un proyecto en Google Cloud y habilitar la API de Text-to-Speech. Luego, descargar la credencial en formato JSON y configurarla como una variable de entorno.\n",
    "\n",
    "- **Paso 1**: Ve a [Google Cloud Console](https://console.cloud.google.com/).\n",
    "- **Paso 2**: Crea un nuevo proyecto y habilita la API de Text-to-Speech.\n",
    "- **Paso 3**: Crea una clave de servicio en formato JSON y descarga el archivo.\n",
    "- **Paso 4**: Establece la variable de entorno `GOOGLE_APPLICATION_CREDENTIALS` con la ruta de tu archivo de la credencial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Configura la variable de entorno para autenticarte con Google Cloud\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = r\"E:\\proyecto\\TTS-GCP\\CREDENCIAL.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listar las Voces Disponibles\n",
    "Esta sección permite obtener una lista de todas las voces ofrecidas por la API de Google Cloud Text-to-Speech. Para mayor relevancia, se filtran únicamente las voces disponibles en idioma español. Esto facilita la selección de una voz adecuada para la síntesis de texto a voz en este idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voz: es-ES-Journey-D, Idioma: es-ES\n",
      "Voz: es-ES-Journey-F, Idioma: es-ES\n",
      "Voz: es-ES-Journey-O, Idioma: es-ES\n",
      "Voz: es-ES-Neural2-A, Idioma: es-ES\n",
      "Voz: es-ES-Neural2-B, Idioma: es-ES\n",
      "Voz: es-ES-Neural2-C, Idioma: es-ES\n",
      "Voz: es-ES-Neural2-D, Idioma: es-ES\n",
      "Voz: es-ES-Neural2-E, Idioma: es-ES\n",
      "Voz: es-ES-Neural2-F, Idioma: es-ES\n",
      "Voz: es-ES-Neural2-G, Idioma: es-ES\n",
      "Voz: es-ES-Neural2-H, Idioma: es-ES\n",
      "Voz: es-ES-Polyglot-1, Idioma: es-ES\n",
      "Voz: es-ES-Standard-A, Idioma: es-ES\n",
      "Voz: es-ES-Standard-B, Idioma: es-ES\n",
      "Voz: es-ES-Standard-C, Idioma: es-ES\n",
      "Voz: es-ES-Standard-D, Idioma: es-ES\n",
      "Voz: es-ES-Standard-E, Idioma: es-ES\n",
      "Voz: es-ES-Standard-F, Idioma: es-ES\n",
      "Voz: es-ES-Standard-G, Idioma: es-ES\n",
      "Voz: es-ES-Standard-H, Idioma: es-ES\n",
      "Voz: es-ES-Studio-C, Idioma: es-ES\n",
      "Voz: es-ES-Studio-F, Idioma: es-ES\n",
      "Voz: es-ES-Wavenet-B, Idioma: es-ES\n",
      "Voz: es-ES-Wavenet-C, Idioma: es-ES\n",
      "Voz: es-ES-Wavenet-D, Idioma: es-ES\n",
      "Voz: es-ES-Wavenet-E, Idioma: es-ES\n",
      "Voz: es-ES-Wavenet-F, Idioma: es-ES\n",
      "Voz: es-ES-Wavenet-G, Idioma: es-ES\n",
      "Voz: es-ES-Wavenet-H, Idioma: es-ES\n",
      "Voz: es-US-Journey-D, Idioma: es-US\n",
      "Voz: es-US-Journey-F, Idioma: es-US\n",
      "Voz: es-US-Journey-O, Idioma: es-US\n",
      "Voz: es-US-Neural2-A, Idioma: es-US\n",
      "Voz: es-US-Neural2-B, Idioma: es-US\n",
      "Voz: es-US-Neural2-C, Idioma: es-US\n",
      "Voz: es-US-News-D, Idioma: es-US\n",
      "Voz: es-US-News-E, Idioma: es-US\n",
      "Voz: es-US-News-F, Idioma: es-US\n",
      "Voz: es-US-News-G, Idioma: es-US\n",
      "Voz: es-US-Polyglot-1, Idioma: es-US\n",
      "Voz: es-US-Standard-A, Idioma: es-US\n",
      "Voz: es-US-Standard-B, Idioma: es-US\n",
      "Voz: es-US-Standard-C, Idioma: es-US\n",
      "Voz: es-US-Studio-B, Idioma: es-US\n",
      "Voz: es-US-Wavenet-A, Idioma: es-US\n",
      "Voz: es-US-Wavenet-B, Idioma: es-US\n",
      "Voz: es-US-Wavenet-C, Idioma: es-US\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import texttospeech\n",
    "\n",
    "def listar_voces():\n",
    "    client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "    # Obtiene todas las voces disponibles\n",
    "    voices = client.list_voices()\n",
    "\n",
    "    # Filtra las voces que corresponden al idioma español\n",
    "    for voice in voices.voices:\n",
    "        if 'es' in voice.language_codes[0]:\n",
    "            print(f\"Voz: {voice.name}, Idioma: {voice.language_codes[0]}\")\n",
    "\n",
    "# Llama a la función para listar las voces\n",
    "listar_voces()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importación de Bibliotecas\n",
    "\n",
    "importación de las bibliotecas necesarias para interactuar con la API de Google Cloud y para reproducir el archivo de audio generado.\n",
    "\n",
    "- **google.cloud.texttospeech:** Biblioteca para interactuar con la API de Google Cloud Text-to-Speech.\n",
    "- **playsound:** Reproduce el archivo de audio generado.\n",
    "- **os:** Para manejar la ruta de archivo y verificar la existencia del archivo de audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import texttospeech\n",
    "from playsound import playsound # type: ignore\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear Cliente de la API de Text-to-Speech\n",
    "Creamos un cliente de la API de Text-to-Speech para poder realizar las solicitudes de conversión de texto a voz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el cliente de la API de Text-to-Speech\n",
    "client = texttospeech.TextToSpeechClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definir la Función de Síntesis y Reproducción\n",
    "La función `sintetizar_y_reproducir` toma un texto como entrada, lo convierte a voz usando la API de Google y luego reproduce el audio generado. Los parámetros de la función son:\n",
    "\n",
    "- **texto**: El texto que se convertirá a voz.\n",
    "- **nombre_voz**: El nombre de la voz a utilizar. Se puede elegir entre varias voces disponibles (por ejemplo, \"es-ES-Neural2-H\").\n",
    "- **output_file**: El nombre del archivo de salida donde se guardará el audio generado.\n",
    "\n",
    "\n",
    "- **synthesis_input:** El texto que se convertirá a voz.\n",
    "- **voice:** Parámetros de la voz, como el idioma, el nombre de la voz y el género.\n",
    "- **audio_config:** Configuración del audio, donde se define la velocidad de habla (speaking_rate) y el tono de la voz (pitch).\n",
    "- **synthesize_speech():** Método que convierte el texto en audio.\n",
    "- **playsound():** Reproduce el archivo de audio generado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Audio generado y guardado como output00.mp3!\n",
      "Reproducción completada.\n"
     ]
    }
   ],
   "source": [
    "# Función para sintetizar y reproducir el texto\n",
    "def sintetizar_y_reproducir(texto, nombre_voz=\"es-ES-Neural2-H\", output_file=\"output00.mp3\"):\n",
    "    # Configuración de la entrada de texto y voz\n",
    "    synthesis_input = texttospeech.SynthesisInput(text=texto)\n",
    "    voice = texttospeech.VoiceSelectionParams(\n",
    "        language_code=\"es-ES\", \n",
    "        name=nombre_voz, \n",
    "        ssml_gender=texttospeech.SsmlVoiceGender.MALE\n",
    "    )\n",
    "    \n",
    "    # Configuración de velocidad y tono (pitch)\n",
    "    audio_config = texttospeech.AudioConfig(\n",
    "        audio_encoding=texttospeech.AudioEncoding.MP3,\n",
    "        speaking_rate=0.89,  # Velocidad de la voz\n",
    "        pitch=2.90           # Tono de la voz\n",
    "    )\n",
    "\n",
    "    # Sintetizar el texto a voz y guardar el audio\n",
    "    response = client.synthesize_speech(\n",
    "        request={\"input\": synthesis_input, \"voice\": voice, \"audio_config\": audio_config}\n",
    "    )\n",
    "    \n",
    "    # Guardar el archivo de audio\n",
    "    with open(output_file, \"wb\") as out:\n",
    "        out.write(response.audio_content)\n",
    "\n",
    "    print(f\"¡Audio generado y guardado como {output_file}!\")\n",
    "\n",
    "    # Reproducir el archivo de audio\n",
    "    if os.path.exists(output_file):\n",
    "        playsound(output_file)\n",
    "        print(\"Reproducción completada.\")\n",
    "\n",
    "\n",
    "# Texto a sintetizar\n",
    "texto = \"Hola, buenos días Mundo!!!\"\n",
    "\n",
    "# Sintetizar y reproducir\n",
    "sintetizar_y_reproducir(texto, \"es-ES-Neural2-H\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
